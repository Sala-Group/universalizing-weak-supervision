{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7acfe96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "root_path = '../../'\n",
    "sys.path.append(os.path.join(root_path, 'code', 'core'))\n",
    "\n",
    "\n",
    "from ranking_utils import RankingUtils, Ranking\n",
    "from mallows import *\n",
    "from ws_ranking import WeakSupRanking\n",
    "import numpy as np\n",
    "\n",
    "from synth_exp_utils import generate_true_rankings, sample_mallows_LFs, estimate_theta, get_pair_wise_dists\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2422d007",
   "metadata": {},
   "source": [
    "## Generate samples with Mallows model (below is about Mallow's model described by ChatGPT)\n",
    "\n",
    "Mallows' model is a probabilistic model used for ranking and permutation problems. It is named after Colin L. Mallows, who introduced it in 1957. The model is designed to generate permutations of a set of items with a preference for permutations that are closer to a central ranking.\n",
    "\n",
    "### Key Concepts of Mallows' Model\n",
    "\n",
    "1. **Central Ranking ($\\pi_0$)**: The model assumes a central or reference ranking $\\pi_0$, which represents the most likely order of the items.\n",
    "\n",
    "2. **Dispersion Parameter ($\\theta$)**: A parameter $\\theta$ controls the concentration of the distribution around the central ranking. When $\\theta = 0$, all permutations are equally likely. As $\\theta$ increases, the distribution becomes more concentrated around the central ranking.\n",
    "\n",
    "3. **Kendall's Tau Distance**: The model often uses Kendall's tau distance to measure the dissimilarity between a given permutation $\\pi$ and the central ranking $\\pi_0$. Kendall's tau distance is the number of pairwise disagreements between two rankings.\n",
    "\n",
    "### Probability Distribution\n",
    "\n",
    "The probability of a permutation $\\pi$ given the central ranking $\\pi_0$ and the dispersion parameter $\\theta$ is defined as:\n",
    "\n",
    "$$ P(\\pi | \\pi_0, \\theta) = \\frac{1}{Z(\\theta)} \\exp(-\\theta d(\\pi, \\pi_0)) $$\n",
    "\n",
    "where:\n",
    "- $d(\\pi, \\pi_0)$ is the Kendall's tau distance between $\\pi$ and $\\pi_0$.\n",
    "- $Z(\\theta)$ is a normalization constant (partition function) ensuring that the probabilities sum to one. It is given by:\n",
    "$$ Z(\\theta) = \\sum_{\\pi} \\exp(-\\theta d(\\pi, \\pi_0)) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90ae13f",
   "metadata": {},
   "source": [
    "### Parameter setup for LFs with Mallows' Model\n",
    "- Each LF can be represented a Mallows' model with a parameter **Dispersion Parameter ($\\theta$)**. Here we assume each LF is centered, i.e. knows the true center $\\pi_0$.\n",
    "- To see the effectiveness of our label model, we vary noiseness with dispersion parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3416261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15488135 0.17151894 0.16027634 3.63464955 3.2709644  3.93768234]\n"
     ]
    }
   ],
   "source": [
    "num_lfs = 6\n",
    "\n",
    "# Sample true dispersion parameters\n",
    "theta_star = np.zeros(num_lfs)\n",
    "half = int((num_lfs)/2)\n",
    "theta_star[:half] = np.random.uniform(0.1,0.2,half) # Weak dispersion --> less noisy\n",
    "theta_star[half:] = np.random.uniform(2,5,half) # Strong dispersion --> more noisy\n",
    "np.sort(theta_star)\n",
    "print(theta_star)\n",
    "np.random.shuffle(theta_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad243365",
   "metadata": {},
   "source": [
    "### Generate synthetic data from Mallows' model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66f72ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 2, 1], [2, 1, 0], [0, 1, 2]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "d = 3 # the number of items in each example\n",
    "n = 1000 # the number of samples\n",
    "\n",
    "r_utils = RankingUtils(d) # Utility object\n",
    "Y = generate_true_rankings(d,n) # True rankings\n",
    "print(Y[:3])\n",
    "\n",
    "# Note that we use Ranking class defined in\n",
    "# https://github.com/SprocketLab/universalizing-weak-supervision/blob/master/code/core/ranking_utils.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b035b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive type ranking list [[0, 2, 1], [2, 1, 0], [0, 1, 2]] <class 'list'>\n",
      "Ranking object list [[0, 2, 1], [2, 1, 0], [0, 1, 2]] <class 'ranking_utils.Ranking'>\n"
     ]
    }
   ],
   "source": [
    "# Instead of generating samples randomly, suppose we have ranking data.\n",
    "# Here we just extract data from Y to simulate this\n",
    "Y_rankings = [y.permutation for y in Y]\n",
    "print('Naive type ranking list', Y_rankings[:3], type(Y_rankings[0]))\n",
    "\n",
    "# Then, it is required to convert them to Ranking Objects to use UWS pipeline\n",
    "# Convert back by wrapping rank by Ranking object\n",
    "Y = [Ranking(rank) for rank in Y_rankings]\n",
    "print('Ranking object list', Y[:3], type(Y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ca3050",
   "metadata": {},
   "source": [
    "### Sample weak labels from LFs (defined by Mallows' model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f247655a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 0, 1], [1, 2, 0], [0, 2, 1], [0, 2, 1], [2, 0, 1], [0, 2, 1]]\n"
     ]
    }
   ],
   "source": [
    "L = sample_mallows_LFs(Y, num_lfs, theta_star) # list[list[list[Ranking]]]\n",
    "print(L[0]) # 3 items, 6 LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "402d2e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive type LF rankings [[2, 0, 1], [1, 2, 0], [0, 2, 1], [0, 2, 1], [2, 0, 1], [0, 2, 1]] <class 'list'>\n",
      "Ranking object list LF rankings [[2, 0, 1], [1, 2, 0], [0, 2, 1], [0, 2, 1], [2, 0, 1], [0, 2, 1]] <class 'ranking_utils.Ranking'>\n"
     ]
    }
   ],
   "source": [
    "# Instead of generating samples randomly, suppose we have weak ranking labels.\n",
    "# Here we just extract data from L to simulate this.\n",
    "L_rankings = []\n",
    "for lf_rankings in L:\n",
    "    naive_lf_rankings = []\n",
    "    for one_lf_ranking in lf_rankings:\n",
    "        naive_lf_rankings.append(one_lf_ranking.permutation)\n",
    "    L_rankings.append(naive_lf_rankings)\n",
    "print('Naive type LF rankings', L_rankings[0], type(L_rankings[0][0]))\n",
    "\n",
    "# Then, it is required to convert them to Ranking Objects to use UWS pipeline\n",
    "# Convert back by wrapping rank by Ranking object\n",
    "L = []\n",
    "for lf_rankings in L_rankings:\n",
    "    Ranking_lf_rankings = []\n",
    "    for one_lf_ranking in lf_rankings:\n",
    "        Ranking_lf_rankings.append(Ranking(one_lf_ranking))\n",
    "    L.append(Ranking_lf_rankings)\n",
    "print('Ranking object list LF rankings', L[0], type(L[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cc9b2b",
   "metadata": {},
   "source": [
    "### Learn label model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9690b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99635107, 0.92735845, 3.50610817, 3.75047884, 0.90003872,\n",
       "       3.44150772])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_model = WeakSupRanking(r_utils)\n",
    "conf = {\"train_method\":\"median_triplet_opt\"}\n",
    "label_model.train(conf, L, num_lfs) # This process estimates theta\n",
    "label_model.thetas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbdddd7",
   "metadata": {},
   "source": [
    "### Generate aggregated pseudolabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ef48399",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_conf = {\"train_method\":\"median_triplet_opt\", \"inference_rule\": \"kemeny\"}\n",
    "Y_mv = label_model.infer_ranking(mv_conf, L)\n",
    "\n",
    "uws_conf = {\"train_method\":\"median_triplet_opt\", \"inference_rule\": \"weighted_kemeny\"}\n",
    "Y_uws = label_model.infer_ranking(uws_conf, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5291da45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv_kt_dist: 0.07966666666666666 uws_kt_dist: 0.001\n"
     ]
    }
   ],
   "source": [
    "mv_kt_dist = r_utils.mean_kt_distance(Y_mv, Y)\n",
    "uws_kt_dist = r_utils.mean_kt_distance(Y_uws, Y)\n",
    "print('mv_kt_dist:', mv_kt_dist, 'uws_kt_dist:', uws_kt_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78759fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "programmatic-alignment",
   "language": "python",
   "name": "programmatic-alignment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
